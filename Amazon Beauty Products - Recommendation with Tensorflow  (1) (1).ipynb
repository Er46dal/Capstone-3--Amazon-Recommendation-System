{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks \n",
    "   1. Get our data and split it into a training and test set.\n",
    "   2. Implement a ranking model.\n",
    "   3. Fit and evaluate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import tensorflow_datasets as tfds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=tfds.load('amazon_us_reviews/Beauty_v1_00', split='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'customer_id': b'18239070',\n",
      "          'helpful_votes': 0,\n",
      "          'marketplace': b'US',\n",
      "          'product_category': b'Beauty',\n",
      "          'product_id': b'B00LJ86MAY',\n",
      "          'product_parent': b'823234087',\n",
      "          'product_title': b'The Original Curly Tee Towel - T-Shirt Hair Dryi'\n",
      "                           b'ng Towel Wrap (Extra Long)',\n",
      "          'review_body': b'Great product, quick ship and packaged nicely with a'\n",
      "                         b'ttention to detail. Thank you!',\n",
      "          'review_date': b'2014-10-04',\n",
      "          'review_headline': b'Very pleased!',\n",
      "          'review_id': b'R24WHRN0BMM2K7',\n",
      "          'star_rating': 5,\n",
      "          'total_votes': 0,\n",
      "          'verified_purchase': 1,\n",
      "          'vine': 1}}\n"
     ]
    }
   ],
   "source": [
    "for sample in data.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep the features: Customer_id, product_id, and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(lambda x: {\n",
    "        \"customer_id\": x[\"data\"][\"customer_id\"],\n",
    "        \"product_id\": x[\"data\"][\"product_id\"],\n",
    "        \"star_rating\":x[\"data\"][\"star_rating\"]\n",
    "       })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data 80-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = data.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the unique customer and product ids. Also, convert the columns to integers for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = data.batch(1_000_000).map(lambda x: x[\"product_id\"])\n",
    "customers = data.batch(1_000_000).map(lambda x: x[\"customer_id\"])\n",
    "\n",
    "unique_products = np.unique(np.concatenate(list(products)))\n",
    "unique_customers = np.unique(np.concatenate(list(customers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "\n",
    "    # Compute embeddings for users.\n",
    "        self.user_embeddings = tf.keras.Sequential([\n",
    "             tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "        vocabulary=unique_customers, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_customers) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute embeddings for products.\n",
    "        self.product_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "        vocabulary=unique_products, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_products) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute predictions.\n",
    "        self.ratings = tf.keras.Sequential([\n",
    "      # Learn multiple dense layers.\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      # Make rating predictions in the final layer.\n",
    "            tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        customer_id, product_id = inputs\n",
    "        user_embedding = self.user_embeddings(customer_id)\n",
    "        product_embedding = self.product_embeddings(product_id)\n",
    "        return self.ratings(tf.concat([user_embedding, product_embedding], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction for a specific customer and product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['18239070']\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['18239070']\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['B00LJ86MAY']\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['B00LJ86MAY']\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.0135858]], dtype=float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RankingModel()(([\"18239070\"], [\"B00LJ86MAY\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss and Metrics \n",
    "\n",
    "We'll use it together with the MeanSquaredError Keras loss in order to predict the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Ranking(\n",
    "  loss = tf.keras.losses.MeanSquaredError(),\n",
    "  metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Full Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ranking_model: tf.keras.Model = RankingModel()\n",
    "        self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "        loss = tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "       )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        rating_predictions = self.ranking_model(\n",
    "          (features[\"customer_id\"], features[\"product_id\"]))\n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "        return self.task(labels=features[\"star_rating\"], predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting and Evaluating "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the model, we can use standard Keras fitting and evaluation routines to fit and evaluate the model.\n",
    "\n",
    "Let's first instantiate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AmazonModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then shuffle, batch, and cache the training and evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - ETA: 0s - root_mean_squared_error: 4.4026 - loss: 19.3827 - regularization_loss: 0.0000e+00 - total_loss: 19.38 - ETA: 0s - root_mean_squared_error: 4.0841 - loss: 16.6801 - regularization_loss: 0.0000e+00 - total_loss: 16.68 - ETA: 0s - root_mean_squared_error: 3.4435 - loss: 11.8576 - regularization_loss: 0.0000e+00 - total_loss: 11.85 - ETA: 0s - root_mean_squared_error: 3.3079 - loss: 10.9420 - regularization_loss: 0.0000e+00 - total_loss: 10.94 - ETA: 0s - root_mean_squared_error: 3.3842 - loss: 11.4530 - regularization_loss: 0.0000e+00 - total_loss: 11.45 - ETA: 0s - root_mean_squared_error: 3.2706 - loss: 10.6968 - regularization_loss: 0.0000e+00 - total_loss: 10.69 - ETA: 0s - root_mean_squared_error: 3.0872 - loss: 9.5307 - regularization_loss: 0.0000e+00 - total_loss: 9.5307 - ETA: 0s - root_mean_squared_error: 2.9239 - loss: 8.5492 - regularization_loss: 0.0000e+00 - total_loss: 8.54 - ETA: 0s - root_mean_squared_error: 2.7901 - loss: 7.7845 - regularization_loss: 0.0000e+00 - total_loss: 7.78 - ETA: 0s - root_mean_squared_error: 2.7039 - loss: 7.1808 - regularization_loss: 0.0000e+00 - total_loss: 7.18 - 2s 167ms/step - root_mean_squared_error: 2.7039 - loss: 6.6869 - regularization_loss: 0.0000e+00 - total_loss: 6.6869\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - ETA: 0s - root_mean_squared_error: 1.3052 - loss: 1.7036 - regularization_loss: 0.0000e+00 - total_loss: 1.70 - ETA: 0s - root_mean_squared_error: 1.3052 - loss: 1.7037 - regularization_loss: 0.0000e+00 - total_loss: 1.70 - ETA: 0s - root_mean_squared_error: 1.3049 - loss: 1.7027 - regularization_loss: 0.0000e+00 - total_loss: 1.70 - ETA: 0s - root_mean_squared_error: 1.3020 - loss: 1.6953 - regularization_loss: 0.0000e+00 - total_loss: 1.69 - ETA: 0s - root_mean_squared_error: 1.3008 - loss: 1.6921 - regularization_loss: 0.0000e+00 - total_loss: 1.69 - ETA: 0s - root_mean_squared_error: 1.3029 - loss: 1.6975 - regularization_loss: 0.0000e+00 - total_loss: 1.69 - ETA: 0s - root_mean_squared_error: 1.3018 - loss: 1.6946 - regularization_loss: 0.0000e+00 - total_loss: 1.69 - ETA: 0s - root_mean_squared_error: 1.3001 - loss: 1.6904 - regularization_loss: 0.0000e+00 - total_loss: 1.69 - ETA: 0s - root_mean_squared_error: 1.2988 - loss: 1.6868 - regularization_loss: 0.0000e+00 - total_loss: 1.68 - ETA: 0s - root_mean_squared_error: 1.3004 - loss: 1.6922 - regularization_loss: 0.0000e+00 - total_loss: 1.69 - 2s 162ms/step - root_mean_squared_error: 1.3004 - loss: 1.6967 - regularization_loss: 0.0000e+00 - total_loss: 1.6967\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - ETA: 0s - root_mean_squared_error: 1.3038 - loss: 1.7000 - regularization_loss: 0.0000e+00 - total_loss: 1.70 - ETA: 0s - root_mean_squared_error: 1.3042 - loss: 1.7010 - regularization_loss: 0.0000e+00 - total_loss: 1.70 - ETA: 0s - root_mean_squared_error: 1.3040 - loss: 1.7005 - regularization_loss: 0.0000e+00 - total_loss: 1.70 - ETA: 0s - root_mean_squared_error: 1.3013 - loss: 1.6934 - regularization_loss: 0.0000e+00 - total_loss: 1.69 - ETA: 0s - root_mean_squared_error: 1.3001 - loss: 1.6903 - regularization_loss: 0.0000e+00 - total_loss: 1.69 - ETA: 0s - root_mean_squared_error: 1.3023 - loss: 1.6959 - regularization_loss: 0.0000e+00 - total_loss: 1.69 - ETA: 0s - root_mean_squared_error: 1.3012 - loss: 1.6931 - regularization_loss: 0.0000e+00 - total_loss: 1.69 - ETA: 0s - root_mean_squared_error: 1.2996 - loss: 1.6889 - regularization_loss: 0.0000e+00 - total_loss: 1.68 - ETA: 0s - root_mean_squared_error: 1.2982 - loss: 1.6854 - regularization_loss: 0.0000e+00 - total_loss: 1.68 - ETA: 0s - root_mean_squared_error: 1.2999 - loss: 1.6908 - regularization_loss: 0.0000e+00 - total_loss: 1.69 - 2s 165ms/step - root_mean_squared_error: 1.2999 - loss: 1.6953 - regularization_loss: 0.0000e+00 - total_loss: 1.6953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x142d0a4b4c8>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the model trains, the loss is falling and the RMSE metric is improving.\n",
    "\n",
    "Finally, we can evaluate our model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - ETA: 0s - root_mean_squared_error: 1.2972 - loss: 1.6826 - regularization_loss: 0.0000e+00 - total_loss: 1.68 - ETA: 0s - root_mean_squared_error: 1.2950 - loss: 1.6770 - regularization_loss: 0.0000e+00 - total_loss: 1.67 - ETA: 0s - root_mean_squared_error: 1.2965 - loss: 1.6810 - regularization_loss: 0.0000e+00 - total_loss: 1.68 - ETA: 0s - root_mean_squared_error: 1.2971 - loss: 1.6826 - regularization_loss: 0.0000e+00 - total_loss: 1.68 - ETA: 0s - root_mean_squared_error: 1.2964 - loss: 1.6804 - regularization_loss: 0.0000e+00 - total_loss: 1.68 - 1s 198ms/step - root_mean_squared_error: 1.2964 - loss: 1.6789 - regularization_loss: 0.0000e+00 - total_loss: 1.6789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 1.2963738441467285,\n",
       " 'loss': 1.6715973615646362,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 1.6715973615646362}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
